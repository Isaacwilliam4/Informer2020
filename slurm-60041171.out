Args in experiment:
Namespace(activation='gelu', attn='prob', batch_size=32, c_out=90, checkpoints='./checkpoints/', cols=None, d_ff=2048, d_layers=10, d_model=512, data='custom', data_path='sim_graph.csv', dec_in=100, des='simulated_graph_informer_test', detail_freq='d', device_ids=[0, 1, 2, 3], devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', enc_in=100, factor=5, features='M', freq='d', gpu=0, inverse=False, itr=2, label_len=90, learning_rate=0.0001, loss='mse', lradj='type1', mix=True, model='informer', n_heads=8, num_workers=8, output_attention=False, padding=0, patience=3, pred_len=24, root_path='./data/', s_layers=[3, 2, 1], seq_len=90, target='none', train_epochs=1000, use_amp=False, use_gpu=True, use_multi_gpu=True)
Use GPU: cuda:0
>>>>>>>start training : informer_custom_ftM_sl90_ll90_pl24_dm512_nh8_el2_dl10_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_simulated_graph_informer_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
features M
train 587
features M
val 78
features M
test 177
Traceback (most recent call last):
  File "./main_informer.py", line 104, in <module>
    exp.train(setting)
  File "/home/isaacwp/Informer2020/exp/exp_informer.py", line 158, in train
    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)
  File "/home/isaacwp/Informer2020/exp/exp_informer.py", line 286, in _process_one_batch
    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 167, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 177, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/_utils.py", line 429, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/isaacwp/Informer2020/models/model.py", line 69, in forward
    enc_out = self.enc_embedding(x_enc, x_mark_enc)
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/isaacwp/Informer2020/models/embed.py", line 107, in forward
    x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/isaacwp/Informer2020/models/embed.py", line 37, in forward
    x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/isaacwp/.conda/envs/informer/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 258, in _conv_forward
    _single(0), self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [512, 100, 3], expected input[8, 90, 92] to have 100 channels, but got 90 channels instead

